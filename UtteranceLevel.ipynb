{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-22 18:39:03.617023: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-22 18:39:04.410874: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-22 18:39:05.774496: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-22 18:39:05.802103: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-22 18:39:05.802306: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'path'\n",
    "input_file1 = 'dev.npy'\n",
    "input_file2 = 'dev_labels.npy'\n",
    "utterances = np.load(\n",
    "    file=os.path.join(path, input_file1),\n",
    "    allow_pickle=True,\n",
    "    encoding='bytes'\n",
    "    )\n",
    "phoneme_states = np.load(\n",
    "    file=os.path.join(path, input_file2),\n",
    "    allow_pickle=True,\n",
    "    encoding='bytes'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training array: (937,) \n",
      "Validation array: (166,)\n"
     ]
    }
   ],
   "source": [
    "rs=121\n",
    "train_utterances, val_utterances, train_phoneme_states, val_phoneme_states = train_test_split(\n",
    "    utterances, phoneme_states,\n",
    "    test_size=0.15,\n",
    "    random_state=rs\n",
    "    )\n",
    "print('Training array:', train_utterances.shape, '\\nValidation array:', val_utterances.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('train.npy', train_utterances)\n",
    "# np.save('train_labels.npy', train_phoneme_states)\n",
    "# np.save('val.npy', val_utterances)\n",
    "# np.save('val_labels.npy', val_phoneme_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138\n"
     ]
    }
   ],
   "source": [
    "unique_phonemes = []\n",
    "for i in train_phoneme_states:\n",
    "    for j in i:\n",
    "        if j not in unique_phonemes:\n",
    "            unique_phonemes.append(j)\n",
    "print(len(unique_phonemes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1738\n"
     ]
    }
   ],
   "source": [
    "num_frames = []\n",
    "for i in utterances:\n",
    "    frames = i.shape[0]\n",
    "    num_frames.append(frames)\n",
    "print(max(num_frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "bingroup": "x",
         "hovertemplate": "x=%{x}<br>count=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "nbinsx": 40,
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "type": "histogram",
         "x": [
          388,
          416,
          467,
          482,
          493,
          477,
          503,
          399,
          463,
          458,
          427,
          479,
          528,
          480,
          445,
          325,
          464,
          478,
          459,
          440,
          436,
          431,
          408,
          414,
          396,
          442,
          448,
          444,
          456,
          457,
          496,
          467,
          462,
          415,
          494,
          441,
          468,
          437,
          418,
          444,
          687,
          641,
          784,
          444,
          886,
          832,
          723,
          945,
          365,
          192,
          451,
          267,
          461,
          608,
          758,
          477,
          192,
          693,
          1041,
          461,
          821,
          152,
          667,
          394,
          520,
          400,
          464,
          691,
          475,
          851,
          834,
          518,
          700,
          404,
          493,
          564,
          478,
          461,
          482,
          865,
          282,
          697,
          547,
          894,
          609,
          574,
          807,
          609,
          954,
          717,
          947,
          1181,
          997,
          503,
          1214,
          280,
          530,
          828,
          914,
          1058,
          801,
          600,
          935,
          860,
          874,
          692,
          370,
          406,
          414,
          460,
          537,
          495,
          488,
          399,
          522,
          467,
          384,
          496,
          512,
          491,
          413,
          356,
          456,
          529,
          461,
          420,
          456,
          390,
          437,
          449,
          387,
          453,
          497,
          490,
          435,
          450,
          479,
          555,
          468,
          416,
          420,
          492,
          491,
          437,
          402,
          445,
          567,
          175,
          357,
          296,
          602,
          383,
          656,
          1049,
          399,
          873,
          475,
          531,
          468,
          978,
          616,
          568,
          706,
          377,
          595,
          803,
          474,
          480,
          432,
          856,
          1108,
          608,
          833,
          635,
          869,
          626,
          691,
          579,
          992,
          872,
          550,
          388,
          650,
          610,
          563,
          1245,
          300,
          443,
          382,
          758,
          595,
          917,
          347,
          1129,
          1097,
          734,
          663,
          431,
          669,
          439,
          819,
          501,
          590,
          618,
          238,
          422,
          400,
          402,
          433,
          477,
          496,
          473,
          405,
          447,
          422,
          415,
          426,
          471,
          448,
          422,
          333,
          463,
          518,
          451,
          394,
          429,
          408,
          406,
          434,
          410,
          466,
          432,
          438,
          470,
          449,
          485,
          437,
          451,
          426,
          421,
          403,
          451,
          403,
          404,
          405,
          1007,
          386,
          694,
          355,
          684,
          440,
          261,
          617,
          346,
          742,
          607,
          712,
          878,
          829,
          495,
          780,
          262,
          612,
          400,
          212,
          128,
          182,
          284,
          302,
          247,
          646,
          544,
          714,
          417,
          695,
          314,
          445,
          554,
          406,
          534,
          866,
          424,
          584,
          416,
          593,
          699,
          493,
          1021,
          1015,
          1174,
          286,
          251,
          461,
          1151,
          1076,
          1051,
          332,
          869,
          462,
          519,
          361,
          906,
          424,
          530,
          480,
          465,
          432,
          470,
          508,
          495,
          479,
          518,
          437,
          449,
          510,
          435,
          498,
          524,
          490,
          448,
          353,
          424,
          499,
          429,
          465,
          443,
          424,
          444,
          434,
          518,
          471,
          459,
          492,
          502,
          471,
          468,
          506,
          454,
          462,
          445,
          493,
          430,
          403,
          478,
          834,
          565,
          767,
          846,
          824,
          601,
          756,
          716,
          491,
          661,
          774,
          309,
          820,
          448,
          762,
          825,
          930,
          952,
          526,
          629,
          434,
          759,
          601,
          672,
          423,
          815,
          493,
          504,
          477,
          324,
          488,
          320,
          583,
          547,
          377,
          1051,
          1230,
          1285,
          635,
          550,
          1004,
          669,
          1526,
          646,
          452,
          643,
          974,
          736,
          893,
          567,
          248,
          673,
          968,
          645,
          1058,
          994,
          1042,
          1269,
          478,
          369,
          990,
          601,
          692,
          1140,
          438,
          852,
          522,
          498,
          459,
          524,
          615,
          635,
          606,
          484,
          537,
          525,
          497,
          516,
          526,
          580,
          569,
          459,
          638,
          673,
          501,
          460,
          468,
          515,
          520,
          559,
          485,
          598,
          563,
          596,
          612,
          549,
          552,
          608,
          604,
          563,
          628,
          532,
          612,
          539,
          488,
          503,
          1394,
          1374,
          389,
          800,
          422,
          988,
          962,
          1101,
          821,
          884,
          835,
          284,
          677,
          427,
          877,
          587,
          849,
          1199,
          1029,
          1051,
          1161,
          476,
          626,
          741,
          298,
          588,
          744,
          647,
          1071,
          792,
          1181,
          695,
          774,
          624,
          1120,
          1062,
          290,
          1426,
          670,
          917,
          1371,
          1025,
          760,
          159,
          1303,
          1183,
          469,
          1738,
          159,
          932,
          1615,
          1009,
          857,
          982,
          516,
          1305,
          1229,
          664,
          674,
          803,
          348,
          635,
          1312,
          1167,
          1414,
          565,
          1128,
          912,
          698,
          993,
          910,
          735,
          999,
          1207,
          398,
          396,
          426,
          438,
          485,
          465,
          469,
          398,
          447,
          435,
          405,
          435,
          479,
          469,
          427,
          349,
          457,
          456,
          441,
          402,
          410,
          409,
          404,
          421,
          386,
          440,
          415,
          414,
          412,
          422,
          432,
          417,
          443,
          395,
          400,
          388,
          461,
          394,
          407,
          421,
          527,
          761,
          362,
          758,
          623,
          292,
          560,
          495,
          672,
          536,
          812,
          372,
          937,
          965,
          587,
          668,
          1003,
          456,
          357,
          140,
          272,
          1024,
          540,
          243,
          650,
          759,
          888,
          652,
          335,
          566,
          350,
          324,
          665,
          335,
          771,
          967,
          636,
          1075,
          654,
          776,
          994,
          697,
          368,
          811,
          269,
          303,
          1437,
          986,
          910,
          630,
          795,
          466,
          762,
          800,
          1017,
          1011,
          202,
          893,
          367,
          941,
          448,
          865,
          1035,
          685,
          1346,
          449,
          902,
          1077,
          552,
          979,
          1040,
          899,
          436,
          743,
          664,
          717,
          1084,
          1292,
          1190,
          1283,
          423,
          421,
          476,
          518,
          540,
          514,
          551,
          492,
          500,
          456,
          514,
          542,
          524,
          486,
          383,
          500,
          553,
          473,
          498,
          478,
          501,
          520,
          446,
          513,
          494,
          516,
          525,
          551,
          532,
          518,
          539,
          509,
          504,
          497,
          502,
          490,
          436,
          480,
          456,
          555,
          700,
          385,
          904,
          674,
          311,
          201,
          281,
          161,
          970,
          403,
          852,
          278,
          604,
          628,
          410,
          427,
          1061,
          289,
          246,
          165,
          709,
          855,
          604,
          721,
          943,
          657,
          726,
          615,
          467,
          407,
          976,
          669,
          626,
          371,
          436,
          515,
          934,
          887,
          627,
          1016,
          1237,
          939,
          1050,
          1143,
          1041,
          776,
          711,
          943,
          1174,
          473,
          986,
          865,
          807,
          1024,
          542,
          1110,
          931,
          916,
          1141,
          547,
          450,
          1067,
          1006,
          697,
          867,
          711,
          390,
          1094,
          577,
          992,
          813,
          470,
          435,
          537,
          542,
          557,
          545,
          547,
          495,
          533,
          517,
          511,
          554,
          560,
          556,
          489,
          537,
          565,
          550,
          453,
          520,
          504,
          525,
          498,
          470,
          576,
          554,
          545,
          601,
          543,
          565,
          515,
          561,
          489,
          522,
          515,
          566,
          546,
          531,
          485,
          750,
          699,
          325,
          445,
          461,
          580,
          1104,
          999,
          657,
          795,
          463,
          646,
          823,
          570,
          605,
          500,
          315,
          857,
          147,
          708,
          612,
          283,
          589,
          449,
          895,
          749,
          788,
          509,
          855,
          578,
          450,
          786,
          1236,
          455,
          891,
          548,
          977,
          943,
          504,
          656,
          605,
          615,
          829,
          1120,
          782,
          914,
          470,
          1568,
          1011,
          270,
          869,
          1135,
          817,
          518,
          869,
          419,
          1019,
          620,
          598,
          1088,
          581,
          814,
          578,
          751,
          308,
          241,
          1246,
          977,
          565,
          841,
          534,
          482,
          677,
          349,
          1125,
          1208,
          577,
          554,
          386,
          369,
          392,
          409,
          442,
          432,
          462,
          373,
          400,
          438,
          372,
          427,
          458,
          419,
          390,
          326,
          436,
          477,
          435,
          398,
          403,
          391,
          406,
          410,
          368,
          464,
          407,
          429,
          425,
          430,
          410,
          429,
          425,
          401,
          390,
          363,
          430,
          371,
          368,
          407,
          730,
          809,
          496,
          653,
          481,
          472,
          494,
          584,
          538,
          283,
          467,
          228,
          370,
          758,
          531,
          476,
          743,
          529,
          745,
          805,
          821,
          562,
          853,
          576,
          869,
          538,
          561,
          507,
          421,
          644,
          614,
          569,
          666,
          462,
          262,
          391,
          328,
          553,
          540,
          787,
          340,
          1376,
          542,
          1137,
          1216,
          471,
          892,
          678,
          899,
          813,
          866,
          308,
          763,
          396,
          194,
          758,
          351,
          667,
          748,
          762,
          723,
          743,
          1050,
          1071,
          939,
          819,
          425,
          579,
          687,
          788,
          427,
          410,
          1358,
          1026,
          632,
          763,
          422,
          424,
          473,
          491,
          503,
          506,
          524,
          421,
          489,
          472,
          474,
          487,
          515,
          482,
          459,
          367,
          496,
          519,
          425,
          462,
          445,
          451,
          490,
          419,
          532,
          502,
          480,
          472,
          492,
          470,
          470,
          487,
          445,
          470,
          473,
          497,
          424,
          437,
          468,
          430,
          545,
          668,
          633,
          386,
          327,
          777,
          1054,
          669,
          322,
          240,
          614,
          295,
          1081,
          691,
          377,
          163,
          129,
          546,
          797,
          699,
          707,
          599,
          1002,
          437,
          772,
          315,
          429,
          710,
          710,
          586,
          380,
          209,
          339,
          399,
          423,
          656,
          588,
          603,
          286,
          950,
          267,
          747,
          990,
          826,
          985,
          184,
          682,
          272,
          1083,
          423,
          510,
          592,
          707,
          284,
          808,
          1148,
          647,
          745,
          758,
          709,
          780,
          482,
          780,
          813,
          467,
          410,
          583,
          763,
          657,
          1011,
          1079,
          439,
          270,
          895,
          569
         ],
         "xaxis": "x",
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "height": 600,
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#f2f5fa"
            },
            "error_y": {
             "color": "#f2f5fa"
            },
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "baxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#506784"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "header": {
             "fill": {
              "color": "#2a3f5f"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#f2f5fa",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#f2f5fa"
          },
          "geo": {
           "bgcolor": "rgb(17,17,17)",
           "lakecolor": "rgb(17,17,17)",
           "landcolor": "rgb(17,17,17)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#506784"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "dark"
          },
          "paper_bgcolor": "rgb(17,17,17)",
          "plot_bgcolor": "rgb(17,17,17)",
          "polar": {
           "angularaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "radialaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "yaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "zaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#f2f5fa"
           }
          },
          "sliderdefaults": {
           "bgcolor": "#C8D4E3",
           "bordercolor": "rgb(17,17,17)",
           "borderwidth": 1,
           "tickwidth": 0
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "caxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "updatemenudefaults": {
           "bgcolor": "#506784",
           "borderwidth": 0
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          }
         }
        },
        "width": 1000,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Frames"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Count"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.histogram(\n",
    "    x=num_frames,\n",
    "    nbins=40\n",
    "    )\n",
    "fig.update_layout(\n",
    "    showlegend=False,\n",
    "    width=1000,\n",
    "    height=600,\n",
    "    template=\"plotly_dark\",\n",
    "    )\n",
    "fig.update_xaxes(title_text='Frames')\n",
    "fig.update_yaxes(title_text='Count')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeechDataGeneratorRNN(tf.keras.utils.Sequence):\n",
    "    def __init__(\n",
    "        self,\n",
    "        filenames,\n",
    "        path = r'path',\n",
    "        max_frames=None,\n",
    "        pad_frames=1738,\n",
    "        batch_size=2,\n",
    "        shuffle=True\n",
    "        ):\n",
    "        self.dataX, self.dataY = self._load_np_arrays(filenames, path)\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle        \n",
    "        self.num_frequencies = self.dataX[0].shape[1]\n",
    "        self.idxMap = []\n",
    "        for utterance_idx in range(self.dataX.shape[0]):\n",
    "            self.idxMap.append(utterance_idx)\n",
    "        self.pad_frames = self._get_max_frames()\n",
    "        if max_frames == None:\n",
    "            self.max_frames = self.pad_frames\n",
    "        else:\n",
    "            self.max_frames = max_frames\n",
    "        self.num_classes = self._get_num_classes()\n",
    "            \n",
    "    def _load_np_arrays(self, filenames, path):\n",
    "        f1, f2 = filenames\n",
    "        utterances = np.load(\n",
    "            file=os.path.join(path, f1),\n",
    "            allow_pickle=True,\n",
    "            encoding='bytes'\n",
    "            )\n",
    "        phoneme_states = np.load(\n",
    "            file=os.path.join(path, f2),\n",
    "            allow_pickle=True,\n",
    "            encoding='bytes'\n",
    "            )\n",
    "        return utterances, phoneme_states\n",
    "    \n",
    "    def _get_max_frames(self):\n",
    "        num_frames = []\n",
    "        for utterance in self.dataX:\n",
    "            frames = utterance.shape[0]\n",
    "            num_frames.append(frames)\n",
    "        return max(num_frames)\n",
    "    \n",
    "    def _get_num_classes(self):\n",
    "        unique_phonemes = []\n",
    "        for i in self.dataY:\n",
    "            for j in i:\n",
    "                if j not in unique_phonemes:\n",
    "                    unique_phonemes.append(j)\n",
    "        return len(unique_phonemes)\n",
    "               \n",
    "    def __getitem__(\n",
    "        self,\n",
    "        batch_idx\n",
    "        ):\n",
    "        batch_idxMap = self.idxMap[batch_idx*self.batch_size : (batch_idx+1)*self.batch_size]\n",
    "        batchedX = np.empty((self.batch_size, self.max_frames, self.num_frequencies))\n",
    "        batchedY = np.empty((self.batch_size, self.max_frames))\n",
    "        for batch_idx, utterance_idx in enumerate(batch_idxMap):\n",
    "            utterance = self.dataX[utterance_idx]\n",
    "            utterance = (utterance - (np.mean(utterance) + 1e-8)) / np.std(utterance)\n",
    "            phoneme_vector = self.dataY[utterance_idx].reshape(-1,1)\n",
    "            pad_size = self.pad_frames - utterance.shape[0]\n",
    "            if pad_size % 2 == 0:\n",
    "                zero_padding = tf.constant([[pad_size//2, pad_size//2,], [0, 0]])\n",
    "            else:\n",
    "                zero_padding = tf.constant([[pad_size//2, pad_size//2 + 1,], [0, 0]])\n",
    "            utterance = tf.pad(\n",
    "                tensor = utterance,\n",
    "                paddings = zero_padding,\n",
    "                mode = \"CONSTANT\"\n",
    "                ).numpy()[:self.max_frames, :]\n",
    "            phoneme_vector = tf.pad(\n",
    "                tensor = phoneme_vector,\n",
    "                paddings = zero_padding,\n",
    "                mode = \"CONSTANT\",\n",
    "                constant_values = self.num_classes\n",
    "                ).numpy()[:self.max_frames, :].reshape(-1,)\n",
    "            batchedX[batch_idx,] = utterance\n",
    "            batchedY[batch_idx,] = phoneme_vector\n",
    "        return batchedX, batchedY\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.idxMap) // self.batch_size\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.idxMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "train_data_generator = SpeechDataGeneratorRNN(\n",
    "    filenames=('train.npy', 'train_labels.npy'),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    "    )\n",
    "val_data_generator = SpeechDataGeneratorRNN(\n",
    "    filenames=('val.npy', 'val_labels.npy'),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    "    )    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"RNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_2 (SimpleRNN)    (None, None, 64)          6720      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, None, 139)         9035      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15755 (61.54 KB)\n",
      "Trainable params: 15755 (61.54 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn = tf.keras.Sequential()\n",
    "rnn.add(tf.keras.Input(shape=(None, train_data_generator.num_frequencies)))\n",
    "rnn.add(\n",
    "    tf.keras.layers.SimpleRNN(64, return_sequences=True, activation='tanh')\n",
    "    )\n",
    "rnn.add(\n",
    "    tf.keras.layers.Dense(len(unique_phonemes)+1)\n",
    "    )\n",
    "rnn._name = \"RNN\"\n",
    "rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468/468 [==============================] - 388s 827ms/step - loss: 1.5484 - accuracy: 0.6854 - val_loss: 1.4868 - val_accuracy: 0.6947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f8898da2ac0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.compile(\n",
    "    optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"]\n",
    "    )\n",
    "rnn.fit(\n",
    "    x=train_data_generator,\n",
    "    validation_data=val_data_generator,\n",
    "    epochs=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIDIRECTIONAL RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Bidirectional_RNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirection  (None, None, 128)         13440     \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, None, 139)         17931     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31371 (122.54 KB)\n",
      "Trainable params: 31371 (122.54 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_bidirectional = tf.keras.Sequential()\n",
    "rnn_bidirectional.add(tf.keras.Input(shape=(None, train_data_generator.num_frequencies)))\n",
    "rnn_bidirectional.add(\n",
    "    tf.keras.layers.Bidirectional(\n",
    "        tf.keras.layers.SimpleRNN(64, return_sequences=True, activation='tanh')\n",
    "        )\n",
    "    )\n",
    "rnn_bidirectional.add(\n",
    "    tf.keras.layers.Dense(len(unique_phonemes)+1)\n",
    "    )\n",
    "rnn_bidirectional._name = \"Bidirectional_RNN\"\n",
    "rnn_bidirectional.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468/468 [==============================] - 790s 2s/step - loss: 1.3954 - accuracy: 0.6964 - val_loss: 1.2103 - val_accuracy: 0.7157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f88d0a5dd30>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_bidirectional.compile(\n",
    "    optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"]\n",
    "    )\n",
    "rnn_bidirectional.fit(\n",
    "    x=train_data_generator,\n",
    "    validation_data=val_data_generator,\n",
    "    epochs=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"GRU\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (None, None, 64)          20352     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, None, 139)         9035      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29387 (114.79 KB)\n",
      "Trainable params: 29387 (114.79 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gru = tf.keras.Sequential()\n",
    "gru.add(tf.keras.Input(shape=(None, train_data_generator.num_frequencies)))\n",
    "gru.add(\n",
    "    tf.keras.layers.GRU(64, return_sequences=True, activation='tanh')\n",
    "    )\n",
    "gru.add(\n",
    "    tf.keras.layers.Dense(len(unique_phonemes)+1)\n",
    "    )\n",
    "gru._name = \"GRU\"\n",
    "gru.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-21 16:11:40.548919: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468/468 [==============================] - 26s 40ms/step - loss: 1.4700 - accuracy: 0.7079 - val_loss: 1.1502 - val_accuracy: 0.7229\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f88d0228070>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru.compile(\n",
    "    optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"]\n",
    "    )\n",
    "gru.fit(\n",
    "    x=train_data_generator,\n",
    "    validation_data=val_data_generator,\n",
    "    epochs=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIDIRECTIONAL GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Bidirectional_GRU\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_1 (Bidirecti  (None, None, 128)         40704     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, None, 139)         17931     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58635 (229.04 KB)\n",
      "Trainable params: 58635 (229.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gru_bidirectional = tf.keras.Sequential()\n",
    "gru_bidirectional.add(tf.keras.Input(shape=(None, train_data_generator.num_frequencies)))\n",
    "gru_bidirectional.add(\n",
    "    tf.keras.layers.Bidirectional(\n",
    "        tf.keras.layers.GRU(64, return_sequences=True, activation='tanh')\n",
    "        )\n",
    "    )\n",
    "gru_bidirectional.add(\n",
    "    tf.keras.layers.Dense(len(unique_phonemes)+1)\n",
    "    )\n",
    "gru_bidirectional._name = \"Bidirectional_GRU\"\n",
    "gru_bidirectional.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468/468 [==============================] - 37s 73ms/step - loss: 1.3091 - accuracy: 0.7271 - val_loss: 1.0001 - val_accuracy: 0.7498\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f88c18867c0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_bidirectional.compile(\n",
    "    optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"]\n",
    "    )\n",
    "gru_bidirectional.fit(\n",
    "    x=train_data_generator,\n",
    "    validation_data=val_data_generator,\n",
    "    epochs=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LSTM\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, None, 64)          26880     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, None, 139)         9035      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 35915 (140.29 KB)\n",
      "Trainable params: 35915 (140.29 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm = tf.keras.Sequential()\n",
    "lstm.add(tf.keras.Input(shape=(None, train_data_generator.num_frequencies)))\n",
    "lstm.add(\n",
    "    tf.keras.layers.LSTM(64, return_sequences=True, activation='tanh')\n",
    "    )\n",
    "lstm.add(\n",
    "    tf.keras.layers.Dense(len(unique_phonemes)+1)\n",
    "    )\n",
    "lstm._name = 'LSTM'\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468/468 [==============================] - 21s 41ms/step - loss: 1.4632 - accuracy: 0.7056 - val_loss: 1.1702 - val_accuracy: 0.7218\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f88a41c5fa0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.compile(\n",
    "    optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"]\n",
    "    )\n",
    "lstm.fit(\n",
    "    x=train_data_generator,\n",
    "    validation_data=val_data_generator,\n",
    "    epochs=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIDIRECTIONAL LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Bidirectional_LSTM\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_2 (Bidirecti  (None, None, 128)         53760     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, None, 139)         17931     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 71691 (280.04 KB)\n",
      "Trainable params: 71691 (280.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm_bidirectional = tf.keras.Sequential()\n",
    "lstm_bidirectional.add(tf.keras.Input(shape=(None, train_data_generator.num_frequencies)))\n",
    "lstm_bidirectional.add(\n",
    "    tf.keras.layers.Bidirectional(\n",
    "        tf.keras.layers.LSTM(64, return_sequences=True, activation='tanh')\n",
    "        )\n",
    "    )\n",
    "lstm_bidirectional.add(\n",
    "    tf.keras.layers.Dense(len(unique_phonemes)+1)\n",
    "    )\n",
    "lstm_bidirectional._name = 'Bidirectional_LSTM'\n",
    "lstm_bidirectional.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468/468 [==============================] - 39s 77ms/step - loss: 1.3028 - accuracy: 0.7255 - val_loss: 1.0131 - val_accuracy: 0.7480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f889dbc0820>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_bidirectional.compile(\n",
    "    optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"]\n",
    "    )\n",
    "lstm_bidirectional.fit(\n",
    "    x=train_data_generator,\n",
    "    validation_data=val_data_generator,\n",
    "    epochs=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIDIRECTIONAL GRU & BIDIRECTIONAL LSTM both performed better than the rest, plus they are time saving too in comparison with RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeechDataGeneratorRNN(tf.keras.utils.Sequence):\n",
    "    def __init__(\n",
    "        self,\n",
    "        filenames,\n",
    "        path = r'path',\n",
    "        max_frames=None,\n",
    "        batch_size=2,\n",
    "        shuffle=True\n",
    "        ):\n",
    "        self.dataX, self.dataY = self._load_np_arrays(filenames, path)\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle        \n",
    "        self.num_frequencies = self.dataX[0].shape[1]\n",
    "        self.idxMap = []\n",
    "        for utterance_idx in range(self.dataX.shape[0]):\n",
    "            self.idxMap.append(utterance_idx)\n",
    "        self.pad_frames = self._get_max_frames()\n",
    "        if max_frames == None:\n",
    "            self.max_frames = self.pad_frames\n",
    "        else:\n",
    "            self.max_frames = max_frames\n",
    "        self.num_classes = self._get_num_classes()\n",
    "            \n",
    "    def _load_np_arrays(self, filenames, path):\n",
    "        f1, f2 = filenames\n",
    "        utterances = np.load(\n",
    "            file=os.path.join(path, f1),\n",
    "            allow_pickle=True,\n",
    "            encoding='bytes'\n",
    "            )\n",
    "        phoneme_states = np.load(\n",
    "            file=os.path.join(path, f2),\n",
    "            allow_pickle=True,\n",
    "            encoding='bytes'\n",
    "            )\n",
    "        return utterances, phoneme_states\n",
    "    \n",
    "    def _get_max_frames(self):\n",
    "        num_frames = []\n",
    "        for utterance in self.dataX:\n",
    "            frames = utterance.shape[0]\n",
    "            num_frames.append(frames)\n",
    "        return max(num_frames)\n",
    "    \n",
    "    def _get_num_classes(self):\n",
    "        unique_phonemes = []\n",
    "        for i in self.dataY:\n",
    "            for j in i:\n",
    "                if j not in unique_phonemes:\n",
    "                    unique_phonemes.append(j)\n",
    "        return len(unique_phonemes)\n",
    "               \n",
    "    def __getitem__(\n",
    "        self,\n",
    "        batch_idx\n",
    "        ):\n",
    "        batch_idxMap = self.idxMap[batch_idx*self.batch_size : (batch_idx+1)*self.batch_size]\n",
    "        batchedX = np.empty((self.batch_size, self.max_frames, self.num_frequencies))\n",
    "        batchedY = np.empty((self.batch_size, self.max_frames))\n",
    "        for batch_idx, utterance_idx in enumerate(batch_idxMap):\n",
    "            utterance = self.dataX[utterance_idx]\n",
    "            utterance = (utterance - (np.mean(utterance, axis=0) + 1e-8))\n",
    "            phoneme_vector = self.dataY[utterance_idx].reshape(-1,1)\n",
    "            pad_size = self.pad_frames - utterance.shape[0]\n",
    "            zero_padding = tf.constant([[0, pad_size,], [0, 0]])\n",
    "            utterance = tf.pad(\n",
    "                tensor = utterance,\n",
    "                paddings = zero_padding,\n",
    "                mode = \"CONSTANT\"\n",
    "                ).numpy()[:self.max_frames, :]\n",
    "            phoneme_vector = tf.pad(\n",
    "                tensor = phoneme_vector,\n",
    "                paddings = zero_padding,\n",
    "                mode = \"CONSTANT\",\n",
    "                constant_values = self.num_classes\n",
    "                ).numpy()[:self.max_frames, :].reshape(-1,)\n",
    "            batchedX[batch_idx,] = utterance\n",
    "            batchedY[batch_idx,] = phoneme_vector\n",
    "        return batchedX, batchedY\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.idxMap) // self.batch_size\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.idxMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1DBlock(tf.keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        out_channels,\n",
    "        kernel_size=3,\n",
    "        include_bn=True\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.conv = tf.keras.layers.Conv1D(out_channels, kernel_size, padding='same')\n",
    "        self.act = tf.nn.tanh\n",
    "        self.include_bn = include_bn\n",
    "        self.dropout = tf.nn.dropout\n",
    "        if self.include_bn == True:\n",
    "            self.bn = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "    def call(\n",
    "        self,\n",
    "        input_tensor,\n",
    "        training=False\n",
    "        ):\n",
    "        rate = 0.3\n",
    "        x = self.conv(input_tensor, training=training)\n",
    "        x = self.act(x)\n",
    "        # x = self.act(x, beta=beta)\n",
    "        x = self.dropout(x, rate=rate)\n",
    "        if self.include_bn == True:\n",
    "            return self.bn(x, training=training)\n",
    "        else:\n",
    "            return x \n",
    "    \n",
    "class ResidualConv1DBlock(tf.keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        block_channels\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.cnn_blocks = [Conv1DBlock(out_channels) for out_channels in block_channels] \n",
    "        self.pooling = tf.keras.layers.MaxPooling1D()\n",
    "        self.skip_connection = tf.keras.layers.Conv1D(\n",
    "            block_channels[-1],\n",
    "            1,\n",
    "            padding='same'\n",
    "            )\n",
    "        self.act = tf.nn.tanh\n",
    "        self.bn = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "    def call(\n",
    "        self,\n",
    "        input_tensor,\n",
    "        training=False,\n",
    "        ):\n",
    "        leak = 0.02\n",
    "        x = tf.keras.Sequential(self.cnn_blocks)(input_tensor, training=training)\n",
    "        x = self.act(x + self.skip_connection(input_tensor))\n",
    "        return self.bn(x)\n",
    "\n",
    "class BiLSTMBlock(tf.keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        units,\n",
    "        include_bn=True,\n",
    "        include_bi=True\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.include_bn = include_bn\n",
    "        if include_bi:\n",
    "            self.lstm = tf.keras.layers.Bidirectional(\n",
    "                tf.compat.v1.keras.layers.CuDNNGRU(\n",
    "                    units,\n",
    "                    kernel_regularizer=tf.keras.regularizers.L2(1e-3),\n",
    "                    return_sequences=True\n",
    "                    ),\n",
    "                merge_mode='concat'  \n",
    "                )\n",
    "        else:\n",
    "            self.lstm = tf.compat.v1.keras.layers.CuDNNGRU(\n",
    "                units,\n",
    "                kernel_regularizer=tf.keras.regularizers.L2(1e-3),\n",
    "                return_sequences=True\n",
    "                )              \n",
    "        self.act = tf.nn.tanh\n",
    "        self.dropout = tf.nn.dropout\n",
    "        if self.include_bn:\n",
    "            self.bn = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "    def call(\n",
    "        self,\n",
    "        input_tensor,\n",
    "        training=False\n",
    "        ):\n",
    "        rate = 0.4\n",
    "        x = self.lstm(input_tensor, training=training)\n",
    "        x = self.act(x)\n",
    "        x = self.dropout(x, rate=rate)\n",
    "        if self.include_bn:\n",
    "            return self.bn(x, training=training)\n",
    "        else:\n",
    "            return x \n",
    "        # return x\n",
    "        \n",
    "class ResidualBiLSTMBlock(tf.keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        block_units\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.lstm_blocks = [BiLSTMBlock(units) for units in block_units]\n",
    "        self.act = tf.nn.tanh\n",
    "        \n",
    "    def call(\n",
    "        self,\n",
    "        input_tensor,\n",
    "        training=False,\n",
    "        ):\n",
    "        x = tf.keras.Sequential(self.lstm_blocks)(input_tensor, training=training)\n",
    "        x = self.act(x + input_tensor)\n",
    "        return x\n",
    "\n",
    "class Conv1DLSTMModel(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        blocks_channels,\n",
    "        blocks_units,\n",
    "        train_data_generator,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.train_data_generator = train_data_generator\n",
    "        self.resconv_blocks = [ResidualConv1DBlock(block_channels) for block_channels in blocks_channels]\n",
    "        self.reslstm_layers = [ResidualBiLSTMBlock(block_units) for block_units in blocks_units] \n",
    "        self.classifier = tf.keras.layers.Dense(train_data_generator.num_classes + 1, name='Output_Layer')\n",
    "        \n",
    "    def call(\n",
    "        self,\n",
    "        input_tensor,\n",
    "        training=False\n",
    "        ):\n",
    "        x = tf.keras.Sequential(self.resconv_blocks)(input_tensor, training=training)\n",
    "        x = tf.keras.Sequential(self.reslstm_layers)(x, training=training)\n",
    "        return self.classifier(x)\n",
    "    \n",
    "    def model(\n",
    "        self\n",
    "        ):\n",
    "        x = tf.keras.layers.Input(\n",
    "            shape=(self.train_data_generator.max_frames, self.train_data_generator.num_frequencies),\n",
    "            batch_size=self.train_data_generator.batch_size,\n",
    "            name=\"Input_Layer\"\n",
    "            )\n",
    "        return tf.keras.Model(\n",
    "            inputs=[x],\n",
    "            outputs=self.call(x)    \n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "max_frames = 1000\n",
    "train_data_generator = SpeechDataGeneratorRNN(\n",
    "    filenames=('train.npy', 'train_labels.npy'),\n",
    "    batch_size=batch_size,\n",
    "    max_frames=max_frames,\n",
    "    shuffle=True\n",
    "    )\n",
    "val_data_generator = SpeechDataGeneratorRNN(\n",
    "    filenames=('val.npy', 'val_labels.npy'),\n",
    "    batch_size=batch_size,\n",
    "    max_frames=max_frames,\n",
    "    shuffle=True\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_Layer (InputLayer)    [(4, 1000, 40)]           0         \n",
      "                                                                 \n",
      " sequential_6 (Sequential)   (4, 1000, 256)            43520     \n",
      "                                                                 \n",
      " sequential_7 (Sequential)   (4, 1000, 256)            297472    \n",
      "                                                                 \n",
      " Output_Layer (Dense)        (4, 1000, 139)            35723     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 376715 (1.44 MB)\n",
      "Trainable params: 375179 (1.43 MB)\n",
      "Non-trainable params: 1536 (6.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_lstm = Conv1DLSTMModel(\n",
    "    blocks_channels=[\n",
    "        [128, 256],\n",
    "        [128, 256],\n",
    "        ],\n",
    "    blocks_units=[\n",
    "        [128, 128],\n",
    "        ],\n",
    "    train_data_generator=train_data_generator,\n",
    "    ).model()\n",
    "base_input = conv_lstm.layers[0].input\n",
    "base_output = conv_lstm.layers[-1].output\n",
    "conv_lstm = tf.keras.Model(base_input, base_output)\n",
    "conv_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "initial_learning_rate = 1e-3\n",
    "final_learning_rate = 9e-4\n",
    "learning_rate_decay_factor = (final_learning_rate / initial_learning_rate)**(1/epochs)\n",
    "steps_per_epoch = train_data_generator.__len__()\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=initial_learning_rate,\n",
    "    decay_steps=steps_per_epoch,\n",
    "    decay_rate=learning_rate_decay_factor,\n",
    "    staircase=True\n",
    "    )\n",
    "conv_lstm.compile(\n",
    "    optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=lr_schedule,\n",
    "                                              clipvalue=0.25,\n",
    "                                              clipnorm=1\n",
    "                                              ),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_lstm_history = conv_lstm.fit(\n",
    "    x=train_data_generator,\n",
    "    validation_data=val_data_generator,\n",
    "    epochs=epochs,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
